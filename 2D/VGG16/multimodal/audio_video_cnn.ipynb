{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SP57JsruRqX5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/aashiarv/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from einops.layers.torch import Rearrange\n",
    "from einops import rearrange\n",
    "from facenet_pytorch import MTCNN\n",
    "from self_attention_cv import TransformerEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import face_alignment\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7439\n"
     ]
    }
   ],
   "source": [
    "!ls 'Videos7439' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7439\n"
     ]
    }
   ],
   "source": [
    "!ls 'Spectrograms7439' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_folder = 'Videos7439'\n",
    "spectrograms_folder = 'Spectrograms7439'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oLkWoD6pRrAb"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = models.vgg16(pretrained=True)\n",
    "        # Modify the first layer to accept 6 channel input\n",
    "        self.features.features[0] = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Modify the final layer to output the desired number of classes\n",
    "        self.features.classifier[6] = nn.Linear(self.features.classifier[6].in_features, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gWDrEH00iv6H"
   },
   "outputs": [],
   "source": [
    "def extract_frame(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    mid_frame_index = frame_count // 2  # Index of the frame in the middle of the video\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame_index)\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cap.release()\n",
    "        return frame\n",
    "    else:\n",
    "        cap.release()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_eeDIIORixs-"
   },
   "outputs": [],
   "source": [
    "def detect_face(frame):\n",
    "    mtcnn = MTCNN()\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "    if boxes is not None:\n",
    "        # Assuming only one face in the frame\n",
    "        box = boxes[0]\n",
    "        x1, y1, x2, y2 = box\n",
    "        # Crop the frame to the detected face\n",
    "        cropped_frame = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "        return cropped_frame\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o5gBfMkuitP0"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(frame):\n",
    "    # Convert the frame to a PIL Image\n",
    "    frame_pil = Image.fromarray(frame.astype('uint8'))\n",
    "\n",
    "    # Convert the image to RGB by duplicating channels\n",
    "    frame_pil = frame_pil.convert('RGB')\n",
    "\n",
    "    # Resize and normalize the frame\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization for RGB\n",
    "    ])\n",
    "    img_tensor = transform(frame_pil)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x5iAGoZ_yUMX"
   },
   "outputs": [],
   "source": [
    "def preprocess_spectrogram(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')  # Convert to RGB by duplicating channels\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to match VGG input size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization for RGB\n",
    "    ])\n",
    "    img_tensor = transform(img)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ONxd6uaQyYT8"
   },
   "outputs": [],
   "source": [
    "def load_spectrogram_dataset(spectrograms_folder, skipped_files):\n",
    "    X = []\n",
    "    y = []\n",
    "    # List all files in the input folder\n",
    "    files = sorted(os.listdir(spectrograms_folder))\n",
    "    # Iterate over files in the folder\n",
    "    for filename in tqdm(files):\n",
    "        if filename.endswith(\".png\") and filename[:-3] not in skipped_files:  # Assuming mel spectrograms are stored as PNG files\n",
    "            input_path = os.path.join(spectrograms_folder, filename)\n",
    "            img_tensor = preprocess_spectrogram(input_path)\n",
    "            X.append(img_tensor)\n",
    "            # Extract label from filename (assuming filename is in format \"abc_IEO_label_xyz.png\")\n",
    "            label = filename.split(\"_\")[2]\n",
    "            if label == \"HAP\":\n",
    "                y.append(0)\n",
    "            elif label == \"SAD\":\n",
    "                y.append(1)\n",
    "            elif label == \"ANG\":\n",
    "                y.append(2)\n",
    "            elif label == \"DIS\":\n",
    "                y.append(3)\n",
    "            elif label == \"FEA\":\n",
    "                y.append(4)\n",
    "            elif label == \"NEU\":\n",
    "                y.append(5)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RZPMwNWJi5p3"
   },
   "outputs": [],
   "source": [
    "def load_dataset(videos_folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    skipped_files = []\n",
    "    video_files = [file for file in sorted(os.listdir(videos_folder)) if file.endswith(\".flv\")]\n",
    "    for video_file in tqdm(video_files):\n",
    "        video_path = os.path.join(videos_folder, video_file)\n",
    "        frame = extract_frame(video_path)\n",
    "        if frame is not None:\n",
    "            cropped_face = detect_face(frame)\n",
    "            if cropped_face is not None:\n",
    "                preprocessed_face = preprocess_image(cropped_face)\n",
    "                X.append(preprocessed_face)\n",
    "                label = video_file.split(\"_\")[2].split(\".\")[0]  # Adjusted to handle different file extensions\n",
    "                if label == \"HAP\":\n",
    "                    y.append(0)\n",
    "                elif label == \"SAD\":\n",
    "                    y.append(1)\n",
    "                elif label == \"ANG\":\n",
    "                    y.append(2)\n",
    "                elif label == \"DIS\":\n",
    "                    y.append(3)\n",
    "                elif label == \"FEA\":\n",
    "                    y.append(4)\n",
    "                elif label == \"NEU\":\n",
    "                    y.append(5)\n",
    "            else:\n",
    "                print(f\"No face detected in {video_file}. Skipping.\")\n",
    "                skipped_files.append(video_file[:-3])\n",
    "        else:\n",
    "            print(f\"Failed to extract frame from {video_file}. Skipping.\")\n",
    "            skipped_files.append(video_file[:-3])\n",
    "    return X, y, skipped_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ConcatDataset class to concatenate video frame and spectrogram tensors\n",
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X1, X2, y, modality='multimodal', fullscale=False):\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.y = y\n",
    "        self.modality = modality\n",
    "        self.fullscale = fullscale\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.fullscale:\n",
    "            img1 = torch.from_numpy(self.X1[idx]).float()  # Convert numpy array to torch tensor\n",
    "            img2 = torch.from_numpy(self.X2[idx]).float()  # Convert numpy array to torch tensor\n",
    "            label = torch.tensor(self.y[idx])  # Convert numpy array to torch tensor\n",
    "        else:\n",
    "            img1 = torch.from_numpy(self.X1[idx]).float()  # Convert numpy array to torch tensor\n",
    "            img2 = torch.from_numpy(self.X2[idx]).float()  # Convert numpy array to torch tensor\n",
    "            label = torch.tensor(self.y[idx])  # Convert numpy array to torch tensor\n",
    "\n",
    "        concatenated_img = torch.cat((img1, img2), dim=0)  # Concatenate along 0 dimension\n",
    "        if self.modality == 'visual':\n",
    "            return img1, label\n",
    "        if self.modality == 'audio':\n",
    "            return img2, label\n",
    "        return concatenated_img, label # concatenate modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "O0bI2bJNzZ9r"
   },
   "outputs": [],
   "source": [
    "# # Define the ConcatDataset class to concatenate video frame and spectrogram tensors\n",
    "# class ConcatDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, X1, X2, y, modality='multimodal', fullscale=False):\n",
    "#         self.X1 = X1\n",
    "#         self.X2 = X2\n",
    "#         self.y = y\n",
    "#         self.modality = modality\n",
    "#         self.fullscale = fullscale\n",
    "#     def __len__(self):\n",
    "#         return len(self.y)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if not self.fullscale:\n",
    "#             img1 = torch.from_numpy(self.X1[idx]).float()  # Convert numpy array to torch tensor\n",
    "#             img2 = torch.from_numpy(self.X2[idx]).float()  # Convert numpy array to torch tensor\n",
    "#             label = torch.tensor(self.y[idx])  # Convert numpy array to torch tensor\n",
    "#         else:\n",
    "#             img1 = torch.from_numpy(self.X1[idx]).float()  # Convert numpy array to torch tensor\n",
    "#             img2 = torch.from_numpy(self.X2[idx]).float()  # Convert numpy array to torch tensor\n",
    "#             label = torch.tensor(self.y[idx])  # Convert numpy array to torch tensor\n",
    "\n",
    "#         concatenated_img = torch.cat((img1, img2), dim=0)  # Concatenate along 0 dimension\n",
    "#         if self.modality == 'visual':\n",
    "#             return img1, label\n",
    "#         if self.modality == 'audio':\n",
    "#             return img2, label\n",
    "#         return concatenated_img, label # concatenate modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Q5--S5JwTTw1"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "        total_preds += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    accuracy = correct_preds / total_preds\n",
    "    return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ajpo8J6kTUjD"
   },
   "outputs": [],
   "source": [
    "def test_model(model, criterion, test_loader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    accuracy = correct_preds / total_preds\n",
    "    return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D29Ahtfz2HAb",
    "outputId": "b216ccd4-3f4e-479a-87e6-07f9821502cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 7429\n",
      "Number of train samples (video): 5200 Number of test samples: 2229\n",
      "Number of train samples (audio): 5200 Number of test samples: 2229\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  # Load numpy arrays with memory-mapping\n",
    "X = np.load('X.npy', mmap_mode='r')\n",
    "y = np.load('y.npy', mmap_mode='r')\n",
    "X_spec = np.load('X_spec.npy', mmap_mode='r')\n",
    "y_spec = np.load('y_spec.npy', mmap_mode='r')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "print(f\"Total number of samples: {len(X)}\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Number of train samples (video): {len(X_train)}\", f\"Number of test samples: {len(X_test)}\")\n",
    "X_train_spec, X_test_spec, y_train_spec, y_test_spec = train_test_split(X_spec, y_spec, test_size=0.3, random_state=42)\n",
    "print(f\"Number of train samples (audio): {len(X_train_spec)}\", f\"Number of test samples: {len(X_test_spec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3xLVy9d2O5d",
    "outputId": "6c6091b3-505e-4ca1-ec80-c589ea46bc49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 32 lr: 1e-05\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = CNN(num_classes=6)  # 3 classes for HAPPY, SAD, ANGRY\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "_lr = 0.00001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=_lr)\n",
    "\n",
    "# Concatenate datasets\n",
    "train_dataset = ConcatDataset(X_train, X_train_spec, y_train)\n",
    "test_dataset = ConcatDataset(X_test, X_test_spec, y_test)\n",
    "\n",
    "# Create data loaders\n",
    "_bs = 32\n",
    "# train_loader = torch.utils.data.DataLoader(list(zip(X_train, y_train)), batch_size=_bs, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(list(zip(X_test, y_test)), batch_size=_bs)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=_bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=_bs)\n",
    "\n",
    "\n",
    "print(f\"Batch size: {_bs}\", f\"lr: {_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0upA86L2S47",
    "outputId": "811d82a8-6bab-4d2e-b3c7-2035b39d5b7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:19<00:00,  8.54it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 20.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 1.7155, Train Accuracy: 0.3012, Test Loss: 1.6418, Test Accuracy: 0.3809\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  8.99it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Train Loss: 1.6222, Train Accuracy: 0.4017, Test Loss: 1.6228, Test Accuracy: 0.4074\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.00it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Train Loss: 1.5605, Train Accuracy: 0.4744, Test Loss: 1.5595, Test Accuracy: 0.4805\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.01it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Train Loss: 1.5101, Train Accuracy: 0.5256, Test Loss: 1.5110, Test Accuracy: 0.5280\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.01it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 1.4680, Train Accuracy: 0.5679, Test Loss: 1.4935, Test Accuracy: 0.5437\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.00it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Train Loss: 1.4376, Train Accuracy: 0.6035, Test Loss: 1.5492, Test Accuracy: 0.4805\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.01it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Train Loss: 1.4076, Train Accuracy: 0.6317, Test Loss: 1.4751, Test Accuracy: 0.5621\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.01it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 1.3652, Train Accuracy: 0.6804, Test Loss: 1.4364, Test Accuracy: 0.6074\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.01it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 1.3456, Train Accuracy: 0.6965, Test Loss: 1.4457, Test Accuracy: 0.5891\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.02it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 1.3068, Train Accuracy: 0.7377, Test Loss: 1.4173, Test Accuracy: 0.6209\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.02it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Train Loss: 1.2933, Train Accuracy: 0.7523, Test Loss: 1.4443, Test Accuracy: 0.5935\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.02it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 1.2666, Train Accuracy: 0.7790, Test Loss: 1.4086, Test Accuracy: 0.6335\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.02it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 1.2500, Train Accuracy: 0.7958, Test Loss: 1.4134, Test Accuracy: 0.6240\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.02it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 1.2338, Train Accuracy: 0.8121, Test Loss: 1.4032, Test Accuracy: 0.6330\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.01it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 1.2174, Train Accuracy: 0.8292, Test Loss: 1.4154, Test Accuracy: 0.6214\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.03it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Train Loss: 1.2096, Train Accuracy: 0.8352, Test Loss: 1.3956, Test Accuracy: 0.6447\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.03it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Train Loss: 1.1944, Train Accuracy: 0.8512, Test Loss: 1.4008, Test Accuracy: 0.6380\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.03it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Train Loss: 1.1878, Train Accuracy: 0.8569, Test Loss: 1.4038, Test Accuracy: 0.6312\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.03it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Train Loss: 1.1777, Train Accuracy: 0.8671, Test Loss: 1.3858, Test Accuracy: 0.6528\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.03it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Train Loss: 1.1657, Train Accuracy: 0.8794, Test Loss: 1.4018, Test Accuracy: 0.6339\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.03it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Train Loss: 1.1542, Train Accuracy: 0.8915, Test Loss: 1.4035, Test Accuracy: 0.6344\n",
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.02it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Train Loss: 1.1560, Train Accuracy: 0.8904, Test Loss: 1.3935, Test Accuracy: 0.6451\n",
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.02it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Train Loss: 1.1507, Train Accuracy: 0.8944, Test Loss: 1.4109, Test Accuracy: 0.6200\n",
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.02it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Train Loss: 1.1418, Train Accuracy: 0.9013, Test Loss: 1.3934, Test Accuracy: 0.6474\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.03it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Train Loss: 1.1335, Train Accuracy: 0.9115, Test Loss: 1.3725, Test Accuracy: 0.6689\n",
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.03it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Train Loss: 1.1332, Train Accuracy: 0.9113, Test Loss: 1.4149, Test Accuracy: 0.6187\n",
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.03it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Train Loss: 1.1344, Train Accuracy: 0.9098, Test Loss: 1.3894, Test Accuracy: 0.6478\n",
      "Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.00it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Train Loss: 1.1290, Train Accuracy: 0.9150, Test Loss: 1.3882, Test Accuracy: 0.6523\n",
      "Epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.03it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Train Loss: 1.1223, Train Accuracy: 0.9231, Test Loss: 1.3818, Test Accuracy: 0.6581\n",
      "Epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.04it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Train Loss: 1.1237, Train Accuracy: 0.9212, Test Loss: 1.3868, Test Accuracy: 0.6519\n",
      "Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.04it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Train Loss: 1.1185, Train Accuracy: 0.9262, Test Loss: 1.3784, Test Accuracy: 0.6595\n",
      "Epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.04it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Train Loss: 1.1157, Train Accuracy: 0.9285, Test Loss: 1.3827, Test Accuracy: 0.6563\n",
      "Epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Train Loss: 1.1226, Train Accuracy: 0.9215, Test Loss: 1.3897, Test Accuracy: 0.6474\n",
      "Epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.04it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Train Loss: 1.1222, Train Accuracy: 0.9221, Test Loss: 1.3710, Test Accuracy: 0.6680\n",
      "Epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Train Loss: 1.1169, Train Accuracy: 0.9271, Test Loss: 1.3757, Test Accuracy: 0.6662\n",
      "Epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Train Loss: 1.1178, Train Accuracy: 0.9269, Test Loss: 1.3898, Test Accuracy: 0.6514\n",
      "Epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Train Loss: 1.1115, Train Accuracy: 0.9327, Test Loss: 1.3993, Test Accuracy: 0.6406\n",
      "Epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.04it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Train Loss: 1.1196, Train Accuracy: 0.9252, Test Loss: 1.3697, Test Accuracy: 0.6676\n",
      "Epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.04it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Train Loss: 1.1199, Train Accuracy: 0.9242, Test Loss: 1.3894, Test Accuracy: 0.6456\n",
      "Epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Train Loss: 1.1122, Train Accuracy: 0.9323, Test Loss: 1.4021, Test Accuracy: 0.6357\n",
      "Epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.04it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Train Loss: 1.1106, Train Accuracy: 0.9340, Test Loss: 1.4133, Test Accuracy: 0.6281\n",
      "Epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Train Loss: 1.1170, Train Accuracy: 0.9277, Test Loss: 1.4023, Test Accuracy: 0.6344\n",
      "Epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Train Loss: 1.1073, Train Accuracy: 0.9377, Test Loss: 1.3712, Test Accuracy: 0.6662\n",
      "Epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 1.1071, Train Accuracy: 0.9375, Test Loss: 1.3702, Test Accuracy: 0.6712\n",
      "Epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.04it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Train Loss: 1.1040, Train Accuracy: 0.9398, Test Loss: 1.3809, Test Accuracy: 0.6577\n",
      "Epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Train Loss: 1.1045, Train Accuracy: 0.9388, Test Loss: 1.3668, Test Accuracy: 0.6729\n",
      "Epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Train Loss: 1.1010, Train Accuracy: 0.9431, Test Loss: 1.3630, Test Accuracy: 0.6770\n",
      "Epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Train Loss: 1.0990, Train Accuracy: 0.9448, Test Loss: 1.3763, Test Accuracy: 0.6640\n",
      "Epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.05it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Train Loss: 1.1055, Train Accuracy: 0.9385, Test Loss: 1.3664, Test Accuracy: 0.6703\n",
      "Epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  9.04it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 22.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Train Loss: 1.1081, Train Accuracy: 0.9356, Test Loss: 1.3785, Test Accuracy: 0.6608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch \" + str(epoch))\n",
    "    train_loss, train_accuracy = train_model(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_accuracy = test_model(model, criterion, test_loader, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9N8B8WXkUdJY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'vgg16_audio_video_'+str(num_epochs)+'_'+str(_bs)+'_'+str(_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIsatL11bPU_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WYN9KsDs8lP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.12.2 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
